---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Shaolei Zhang is currently working toward his Ph.D. degree in the [Key Laboratory of Intelligent Information Processing](http://iip.ict.ac.cn/), [Institute of Computing Technology](https://www.cas.cn/), [Chinese Academy of Sciences](https://www.cas.cn/) (ä¸­å›½ç§‘å­¦é™¢è®¡ç®—æŠ€æœ¯ç ”ç©¶æ‰€), advised by [Yang Feng (å†¯æ´‹)](https://people.ucas.edu.cn/~yangfeng?language=en). He received his bachelor's degree from [Beijing University of Posts and Telecommunications](http://www.bupt.edu.cn/) in 2020, majoring in computer science and technology (åŒ—äº¬é‚®ç”µå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å®éªŒç­). 

His research interests include nature language processing, machine translation, simultaneous translation and large language model. He has published 14 papers at the top international AI/NLP conferences such as ACL, EMNKP, NeurIPS, ICLR, AAAI. He won the first place in the streaming transcription track of AutoSimTrans 2021.


# ğŸ”¥ News
- *2023.09*: &nbsp;ğŸ‰ğŸ‰	<font color=red>One paper</font> is accepted by NeurIPS 2023!
- *2023.06*: &nbsp;ğŸ‰ğŸ‰	Our cross-lingual aligned LLM [<font color=red>BayLing</font>](http://nlp.ict.ac.cn/bayling) is released.
- *2023.05*: &nbsp;ğŸ‰ğŸ‰	<font color=red>Two papers</font> are accepted by ACL 2023.
- *2023.01*: &nbsp;ğŸ‰ğŸ‰	<font color=red>One paper</font> is accepted by ICLR 2023 (spotlight)!
- *2022.10*: &nbsp;ğŸ‰ğŸ‰	<font color=red>Three papers</font> are accepted by EMNLP 2022!
- *2022.02*: &nbsp;ğŸ‰ğŸ‰	<font color=red>Three papers</font> are accepted by ACL 2022!

# ğŸ“ Publications 

- ``ACL 2023`` **Shaolei Zhang**, Yang Feng. [End-to-End Simultaneous Speech Translation with Differentiable Segmentation](https://arxiv.org/pdf/2305.16093.pdf). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/DiSeg)
- ``ACL 2023`` Shoutao Guo, **Shaolei Zhang**, Yang Feng. [Learning Optimal Policy for Simultaneous Machine Translation via Binary Search](https://arxiv.org/pdf/2305.12774.pdf). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/BS-SiMT)
- ``ICLR 2022`` **Shaolei Zhang**, Yang Feng. [Hidden Markov Transformer for Simultaneous Machine Translation](https://openreview.net/pdf?id=9y0HFvaAYD6). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/HMT)
- ``EMNLP 2022`` **Shaolei Zhang**, Yang Feng. [Information-Transport-based Policy for Simultaneous Translation](https://arxiv.org/pdf/2210.12357.pdf). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/ITST)
- ``EMNLP 2022`` **Shaolei Zhang**, Shoutao Guo, Yang Feng. [Wait-info Policy: Balancing Source and Target at Information Level for Simultaneous Machine Translation](https://arxiv.org/pdf/2210.11220.pdf). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/Wait-info)
- ``EMNLP 2022`` Shoutao Guo, **Shaolei Zhang**, Yang Feng. [Turning Fixed to Adaptive: Integrating Post-Evaluation into Simultaneous Machine Translation](https://arxiv.org/pdf/2210.11900.pdf). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/PED-SiMT)
- ``ACL 2022`` **Shaolei Zhang**, Yang Feng. [Modeling Dual Read/Write Paths for Simultaneous Machine Translation](https://aclanthology.org/2022.acl-long.176.pdf). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/Dual-Path)
- ``ACL 2022`` **Shaolei Zhang**, Yang Feng. [Reducing Position Bias in Simultaneous Machine Translation with Length-Aware Framework](https://aclanthology.org/2022.acl-long.467.pdf).
- ``ACL 2022`` **Shaolei Zhang**, Yang Feng. [Gaussian Multi-head Attention for Simultaneous Machine Translation](https://aclanthology.org/2022.findings-acl.238.pdf). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/GMA)
- ``EMNLP 2021`` **Shaolei Zhang**, Yang Feng. [Universal Simultaneous Machine Translation with Mixture-of-Experts Wait-k Policy](https://aclanthology.org/2021.emnlp-main.581.pdf). [![github](https://img.shields.io/badge/Code-gray.svg)](https://github.com/ictnlp/MoE-Waitk)
- ``EMNLP 2021`` **Shaolei Zhang**, Yang Feng. [Modeling Concentrated Cross-Attention for Neural Machine Translation with Gaussian Mixture Model](https://aclanthology.org/2021.findings-emnlp.121.pdf).
- ``AutoSimTrans@NAACL 2021`` **Shaolei Zhang**, Yang Feng. [ICTâ€™s System for AutoSimTrans 2021: Robust Char-Level Simultaneous Translation](https://aclanthology.org/2021.autosimtrans-1.1.pdf).
- ``AAAI 2021`` **Shaolei Zhang**, Yang Feng, Liangyou Li. [Future-Guided Incremental Transformer for Simultaneous Translation](https://arxiv.org/pdf/2012.12465.pdf).
- ``ICONIP 2019`` **Shaolei Zhang**, Gang Lu, Kai Shuang. [Opinion Knowledge Injection Network for Aspect Extraction](https://link.springer.com/chapter/10.1007/978-3-030-36711-4_56).


# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
